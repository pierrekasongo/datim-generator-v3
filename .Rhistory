if(nrow(vr_violations) != 0) {
write.csv(vr_violations,file=paste0(outPath,"validation_rule_violations_", format(Sys.time(), "%y-%m-%d"),".csv"))
}
# 5. Check for Duplicates
exact_duplicates <- getExactDuplicates(d)
if(nrow(exact_duplicates) != 0) {
write.csv(exact_duplicates,file=paste0(outPath,"exact_duplicates_", format(Sys.time(), "%y-%m-%d"),".csv"))
}
# 6. Check for indicator / disagg combinations and save the result as a CSV file
invalid_indicators_orgunit <-checkDataElementOrgunitValidity(d,datasets=ds,organisationUnit =organisationUnit)
if(nrow(invalid_indicators_orgunit) != 0) {
write.csv(invalid_indicators_orgunit,file=paste0(outPath,"invalid_indicators_orgunit_",format(Sys.time(), "%y-%m-%d"),".csv"))
}
library(devtools)
library(devtools)
library(devtools)
require(devtools)
install.packages("devtools")
library(devtools)
#install_github("json-p-pickering/datim-validation")
#load_all("C:\\data\\development\\datim-validation") ### Required for SIMS
install_github("jason-p-pickering/datim-validation", force=TRUE)
rm(list=ls())
# To use the script below, make sure you have installed datimvalidation package
# datimvalidation package requires devtools package
# To install devtools packages, open Rstudio and run
#install.packages('devtools')
# To install datimvalidation package, enter the following commands
#install.packages("devtools")
library(devtools)
#install_github("json-p-pickering/datim-validation")
#load_all("C:\\data\\development\\datim-validation") ### Required for SIMS
#install_github("jason-p-pickering/datim-validation", force=TRUE)
require(datimvalidation)
# Set Country UID/Code to validate
organisationUnit = "ANN4YCOufcP"
# set path for your import file here
outPath <- "C:\\DATIM Validation\\"
# Set import file name here e.g TestFile_01.csv
importFile <- paste0(outPath,"datim.csv")
# Set import file type e.g csv or xml or json
importFileType <-"csv"
# Set id/code schemes used in the import file
dataElementIdScheme <- "id"
orgUnitIdScheme <-"id"
idScheme <- "id"
# Set reporting Period
reportingPeriod <-"2018Q4"
# Start processing for Orgunits
secrets<-"C:\\DATIM\\config.json"
loadSecrets(secrets)
#Please change csv to your import file format e.g xml,json to be validated
d<-d2Parser(file=importFile,type = importFileType,
dataElementIdScheme = dataElementIdScheme,orgUnitIdScheme = orgUnitIdScheme,organisationUnit = organisationUnit,idScheme = idScheme,invalidData=TRUE  )
# 1. Check for valid mechanisms and simply print those which are not valid'
invalid_mechanisms <- checkMechanismValidity(d)
if(nrow(invalid_mechanisms) != 0) {
write.csv(invalid_mechanisms,file=paste0(outPath,"invalid_mechanisms_",format(Sys.time(), "%y-%m-%d"),".csv"))
}
# Datasets
ds <- c("zUoy5hk8r0q","PyD4x9oFwxJ","KWRj80vEfHU","fi9yMqWLWVy","IZ71Y2mEBJF","ndp6aR3e1X3","pnlFw2gDGHD","gc4KOv8kGlI","FsYxodZiXyH","iJ4d5HdGiqG")
# 2. Check for indicator / disagg combinations and save the result as a CSV file
invalid_indicators <-checkDataElementDisaggValidity(data=d,datasets=ds)
if(nrow(invalid_indicators) != 0) {
write.csv(invalid_indicators,file=paste0(outPath,"invalid_indicators_",format(Sys.time(), "%y-%m-%d"),".csv"))
}
# 3. Check for indicator / disagg combinations data Types and save the result as a CSV file
bad_data_values<-checkValueTypeCompliance(d)
if(nrow(bad_data_values) != 0) {
write.csv(bad_data_values,file=paste0(outPath,"bad_data_values.csv"))
}
#doMC::registerDoMC(cores=4) # or however many cores you have access to
parallel=FALSE
# 4.Run the validation rule and save the output as a CSV file
vr_violations<-validateData(d,return_violations_only = TRUE, parallel =parallel, datasets = ds)
# Save the validation violations in the same folder and the import file
if(nrow(vr_violations) != 0) {
write.csv(vr_violations,file=paste0(outPath,"validation_rule_violations_", format(Sys.time(), "%y-%m-%d"),".csv"))
}
# 5. Check for Duplicates
exact_duplicates <- getExactDuplicates(d)
if(nrow(exact_duplicates) != 0) {
write.csv(exact_duplicates,file=paste0(outPath,"exact_duplicates_", format(Sys.time(), "%y-%m-%d"),".csv"))
}
# 6. Check for indicator / disagg combinations and save the result as a CSV file
invalid_indicators_orgunit <-checkDataElementOrgunitValidity(d,datasets=ds,organisationUnit =organisationUnit)
if(nrow(invalid_indicators_orgunit) != 0) {
write.csv(invalid_indicators_orgunit,file=paste0(outPath,"invalid_indicators_orgunit_",format(Sys.time(), "%y-%m-%d"),".csv"))
}
rm(list=ls())
# To use the script below, make sure you have installed datimvalidation package
# datimvalidation package requires devtools package
# To install devtools packages, open Rstudio and run
#install.packages('devtools')
# To install datimvalidation package, enter the following commands
#install.packages("devtools")
library(devtools)
#install_github("json-p-pickering/datim-validation")
#load_all("C:\\data\\development\\datim-validation") ### Required for SIMS
#install_github("jason-p-pickering/datim-validation", force=TRUE)
require(datimvalidation)
# Set Country UID/Code to validate
organisationUnit = "ANN4YCOufcP"
# set path for your import file here
outPath <- "C:\\DATIM Validation\\"
# Set import file name here e.g TestFile_01.csv
importFile <- paste0(outPath,"datim.csv")
# Set import file type e.g csv or xml or json
importFileType <-"csv"
# Set id/code schemes used in the import file
dataElementIdScheme <- "id"
orgUnitIdScheme <-"id"
idScheme <- "id"
# Set reporting Period
reportingPeriod <-"2018Q4"
# Start processing for Orgunits
secrets<-"C:\\DATIM\\config.json"
loadSecrets(secrets)
#Please change csv to your import file format e.g xml,json to be validated
d<-d2Parser(file=importFile,type = importFileType,
dataElementIdScheme = dataElementIdScheme,orgUnitIdScheme = orgUnitIdScheme,organisationUnit = organisationUnit,idScheme = idScheme,invalidData=TRUE  )
# 1. Check for valid mechanisms and simply print those which are not valid'
invalid_mechanisms <- checkMechanismValidity(d)
if(nrow(invalid_mechanisms) != 0) {
write.csv(invalid_mechanisms,file=paste0(outPath,"invalid_mechanisms_",format(Sys.time(), "%y-%m-%d"),".csv"))
}
# Datasets
ds <- c("zUoy5hk8r0q","PyD4x9oFwxJ","KWRj80vEfHU","fi9yMqWLWVy","IZ71Y2mEBJF","ndp6aR3e1X3","pnlFw2gDGHD","gc4KOv8kGlI","FsYxodZiXyH","iJ4d5HdGiqG")
# 2. Check for indicator / disagg combinations and save the result as a CSV file
invalid_indicators <-checkDataElementDisaggValidity(data=d,datasets=ds)
if(nrow(invalid_indicators) != 0) {
write.csv(invalid_indicators,file=paste0(outPath,"invalid_indicators_",format(Sys.time(), "%y-%m-%d"),".csv"))
}
# 3. Check for indicator / disagg combinations data Types and save the result as a CSV file
bad_data_values<-checkValueTypeCompliance(d)
if(nrow(bad_data_values) != 0) {
write.csv(bad_data_values,file=paste0(outPath,"bad_data_values.csv"))
}
#doMC::registerDoMC(cores=4) # or however many cores you have access to
parallel=FALSE
# 4.Run the validation rule and save the output as a CSV file
vr_violations<-validateData(d,return_violations_only = TRUE, parallel =parallel, datasets = ds)
# Save the validation violations in the same folder and the import file
if(nrow(vr_violations) != 0) {
write.csv(vr_violations,file=paste0(outPath,"validation_rule_violations_", format(Sys.time(), "%y-%m-%d"),".csv"))
}
# 5. Check for Duplicates
exact_duplicates <- getExactDuplicates(d)
if(nrow(exact_duplicates) != 0) {
write.csv(exact_duplicates,file=paste0(outPath,"exact_duplicates_", format(Sys.time(), "%y-%m-%d"),".csv"))
}
# 6. Check for indicator / disagg combinations and save the result as a CSV file
invalid_indicators_orgunit <-checkDataElementOrgunitValidity(d,datasets=ds,organisationUnit =organisationUnit)
if(nrow(invalid_indicators_orgunit) != 0) {
write.csv(invalid_indicators_orgunit,file=paste0(outPath,"invalid_indicators_orgunit_",format(Sys.time(), "%y-%m-%d"),".csv"))
}
rm(list=ls())
# To use the script below, make sure you have installed datimvalidation package
# datimvalidation package requires devtools package
# To install devtools packages, open Rstudio and run
#install.packages('devtools')
# To install datimvalidation package, enter the following commands
#install.packages("devtools")
library(devtools)
#install_github("json-p-pickering/datim-validation")
#load_all("C:\\data\\development\\datim-validation") ### Required for SIMS
#install_github("jason-p-pickering/datim-validation", force=TRUE)
require(datimvalidation)
# Set Country UID/Code to validate
organisationUnit = "JVafaPfopJf"
# set path for your import file here
outPath <- "C:\\DATIM Validation\\"
# Set import file name here e.g TestFile_01.csv
importFile <- paste0(outPath,"datim.csv")
# Set import file type e.g csv or xml or json
importFileType <-"csv"
# Set id/code schemes used in the import file
dataElementIdScheme <- "id"
orgUnitIdScheme <-"id"
idScheme <- "id"
# Set reporting Period
reportingPeriod <-"2020Q1"
# Start processing for Orgunits
secrets<-"C:\\DATIM\\config.json"
loadSecrets(secrets)
#Please change csv to your import file format e.g xml,json to be validated
d<-d2Parser(file=importFile,type = importFileType,
dataElementIdScheme = dataElementIdScheme,orgUnitIdScheme = orgUnitIdScheme,organisationUnit = organisationUnit,idScheme = idScheme,invalidData=TRUE  )
# 1. Check for valid mechanisms and simply print those which are not valid'
invalid_mechanisms <- checkMechanismValidity(d)
if(nrow(invalid_mechanisms) != 0) {
write.csv(invalid_mechanisms,file=paste0(outPath,"invalid_mechanisms_",format(Sys.time(), "%y-%m-%d"),".csv"))
}
# Datasets
ds <- c("zUoy5hk8r0q","PyD4x9oFwxJ","KWRj80vEfHU","fi9yMqWLWVy","IZ71Y2mEBJF","ndp6aR3e1X3","pnlFw2gDGHD","gc4KOv8kGlI","FsYxodZiXyH","iJ4d5HdGiqG")
# 2. Check for indicator / disagg combinations and save the result as a CSV file
invalid_indicators <-checkDataElementDisaggValidity(data=d,datasets=ds)
if(nrow(invalid_indicators) != 0) {
write.csv(invalid_indicators,file=paste0(outPath,"invalid_indicators_",format(Sys.time(), "%y-%m-%d"),".csv"))
}
# 3. Check for indicator / disagg combinations data Types and save the result as a CSV file
bad_data_values<-checkValueTypeCompliance(d)
if(nrow(bad_data_values) != 0) {
write.csv(bad_data_values,file=paste0(outPath,"bad_data_values.csv"))
}
#doMC::registerDoMC(cores=4) # or however many cores you have access to
parallel=FALSE
# 4.Run the validation rule and save the output as a CSV file
vr_violations<-validateData(d,return_violations_only = TRUE, parallel =parallel, datasets = ds)
# Save the validation violations in the same folder and the import file
if(nrow(vr_violations) != 0) {
write.csv(vr_violations,file=paste0(outPath,"validation_rule_violations_", format(Sys.time(), "%y-%m-%d"),".csv"))
}
# 5. Check for Duplicates
exact_duplicates <- getExactDuplicates(d)
if(nrow(exact_duplicates) != 0) {
write.csv(exact_duplicates,file=paste0(outPath,"exact_duplicates_", format(Sys.time(), "%y-%m-%d"),".csv"))
}
# 6. Check for indicator / disagg combinations and save the result as a CSV file
invalid_indicators_orgunit <-checkDataElementOrgunitValidity(d,datasets=ds,organisationUnit =organisationUnit)
if(nrow(invalid_indicators_orgunit) != 0) {
write.csv(invalid_indicators_orgunit,file=paste0(outPath,"invalid_indicators_orgunit_",format(Sys.time(), "%y-%m-%d"),".csv"))
}
rm(list=ls())
# To use the script below, make sure you have installed datimvalidation package
# datimvalidation package requires devtools package
# To install devtools packages, open Rstudio and run
#install.packages('devtools')
# To install datimvalidation package, enter the following commands
#install.packages("devtools")
library(devtools)
#install_github("json-p-pickering/datim-validation")
#load_all("C:\\data\\development\\datim-validation") ### Required for SIMS
#install_github("jason-p-pickering/datim-validation", force=TRUE)
require(datimvalidation)
# Set Country UID/Code to validate
organisationUnit = "JVafaPfopJf"
# set path for your import file here
outPath <- "C:\\DATIM Validation\\"
# Set import file name here e.g TestFile_01.csv
importFile <- paste0(outPath,"datim.csv")
# Set import file type e.g csv or xml or json
importFileType <-"csv"
# Set id/code schemes used in the import file
dataElementIdScheme <- "id"
orgUnitIdScheme <-"id"
idScheme <- "id"
# Set reporting Period
reportingPeriod <-"2020Q1"
# Start processing for Orgunits
secrets<-"C:\\DATIM\\config.json"
loadSecrets(secrets)
#Please change csv to your import file format e.g xml,json to be validated
d<-d2Parser(file=importFile,type = importFileType,
dataElementIdScheme = dataElementIdScheme,orgUnitIdScheme = orgUnitIdScheme,organisationUnit = organisationUnit,idScheme = idScheme,invalidData=TRUE  )
# 1. Check for valid mechanisms and simply print those which are not valid'
invalid_mechanisms <- checkMechanismValidity(d)
if(nrow(invalid_mechanisms) != 0) {
write.csv(invalid_mechanisms,file=paste0(outPath,"invalid_mechanisms_",format(Sys.time(), "%y-%m-%d"),".csv"))
}
# Datasets
ds <- c("zUoy5hk8r0q","PyD4x9oFwxJ","KWRj80vEfHU","fi9yMqWLWVy","IZ71Y2mEBJF","ndp6aR3e1X3","pnlFw2gDGHD","gc4KOv8kGlI","FsYxodZiXyH","iJ4d5HdGiqG")
# 2. Check for indicator / disagg combinations and save the result as a CSV file
invalid_indicators <-checkDataElementDisaggValidity(data=d,datasets=ds)
if(nrow(invalid_indicators) != 0) {
write.csv(invalid_indicators,file=paste0(outPath,"invalid_indicators_",format(Sys.time(), "%y-%m-%d"),".csv"))
}
# 3. Check for indicator / disagg combinations data Types and save the result as a CSV file
bad_data_values<-checkValueTypeCompliance(d)
if(nrow(bad_data_values) != 0) {
write.csv(bad_data_values,file=paste0(outPath,"bad_data_values.csv"))
}
#doMC::registerDoMC(cores=4) # or however many cores you have access to
parallel=FALSE
# 4.Run the validation rule and save the output as a CSV file
vr_violations<-validateData(d,return_violations_only = TRUE, parallel =parallel, datasets = ds)
# Save the validation violations in the same folder and the import file
if(nrow(vr_violations) != 0) {
write.csv(vr_violations,file=paste0(outPath,"validation_rule_violations_", format(Sys.time(), "%y-%m-%d"),".csv"))
}
# 5. Check for Duplicates
exact_duplicates <- getExactDuplicates(d)
if(nrow(exact_duplicates) != 0) {
write.csv(exact_duplicates,file=paste0(outPath,"exact_duplicates_", format(Sys.time(), "%y-%m-%d"),".csv"))
}
# 6. Check for indicator / disagg combinations and save the result as a CSV file
invalid_indicators_orgunit <-checkDataElementOrgunitValidity(d,datasets=ds,organisationUnit =organisationUnit)
if(nrow(invalid_indicators_orgunit) != 0) {
write.csv(invalid_indicators_orgunit,file=paste0(outPath,"invalid_indicators_orgunit_",format(Sys.time(), "%y-%m-%d"),".csv"))
}
install.packages("shiny")
shiny::runApp('iHAP/DEVELOPMENT/Generator v2')
install.packages("shinycssloaders")
runApp('iHAP/DEVELOPMENT/Generator v2')
install.packages("tidyverse")
install.packages("readxl")
install.packages("openxlsx")
install.packages("lubridate")
runApp('iHAP/DEVELOPMENT/Generator v2')
runApp('iHAP/DEVELOPMENT/Generator v2')
runApp('iHAP/DEVELOPMENT/Generator v2')
runApp('iHAP/DEVELOPMENT/Generator v2')
shiny::runApp('iHAP/DEVELOPMENT/Generator v2')
runApp('iHAP/DEVELOPMENT/Generator v2')
install.packages("shinyjs)
install.packages("shinyjs")
install.packages("shinyjs")
runApp('iHAP/DEVELOPMENT/Generator v2')
runApp('iHAP/DEVELOPMENT/Generator v2')
shiny::runApp('iHAP/DEVELOPMENT/Datim-Generator v2')
shiny::runApp('iHAP/DEVELOPMENT/Generator')
runApp('iHAP/DEVELOPMENT/Generator')
install.packages("RODBC")
install.packages("RMySQL")
#install.packages("RMySQL")
library(RMySQL)
conn <- dbConnect(MySQL(),
user = 'openclinic',
password = '0pen',
host = 'localhost:13306',
dbname = 'openclinic_dbo'
)
summary(conn)
#install.packages("RMySQL")
library(RMySQL)
conn <- dbConnect(MySQL(),
user = 'openclinic',
password = '0pen',
host = 'localhost',
port = '13306',
dbname = 'openclinic_dbo'
)
summary(conn)
#install.packages("RMySQL")
library(RMySQL)
conn <- dbConnect(MySQL(),
user = 'openclinic',
password = '0pen',
host = 'localhost',
port = 13306,
dbname = 'openclinic_dbo'
)
summary(conn)
#install.packages("RMySQL")
library(RMySQL)
conn <- dbConnect(MySQL(),
user = 'openclinic',
password = '0pen',
host = 'localhost',
port = 13306,
dbname = 'openclinic_dbo'
)
dbGetInfo(conn)
#install.packages("RMySQL")
library(RMySQL)
conn <- dbConnect(MySQL(),
user = 'openclinic',
password = '0pen',
host = 'localhost',
port = 13306,
dbname = 'openclinic_dbo'
)
dbListTables(conn)
#install.packages("RMySQL")
library(RMySQL)
conn <- dbConnect(MySQL(),
user = 'openclinic',
password = '0pen',
host = 'localhost',
port = 13306,
dbname = 'openclinic_dbo'
)
dbGetQuery(conn, "SELECT * FROM concepts")
#install.packages("RMySQL")
library(RMySQL)
conn <- dbConnect(MySQL(),
user = 'openclinic',
password = '0pen',
host = 'localhost',
port = 13306,
dbname = 'openclinic_dbo'
)
req <- dbGetQuery(conn, "SELECT * FROM concepts")
dbFetch(req,n=2)
#install.packages("RMySQL")
library(RMySQL)
conn <- dbConnect(MySQL(),
user = 'openclinic',
password = '0pen',
host = 'localhost',
port = 13306,
dbname = 'openclinic_dbo'
)
req <- dbGetQuery(conn, "SELECT * FROM concepts")
data <- dbFetch(req,n=2)
print(data)
#install.packages("RMySQL")
library(RMySQL)
conn <- dbConnect(MySQL(),
user = 'openclinic',
password = '0pen',
host = 'localhost',
port = 13306,
dbname = 'openclinic_dbo'
)
req <- dbGetQuery(conn, "SELECT * FROM concepts")
data <- dbFetch(req,n=2)
print(data.frame(data))
#install.packages("RMySQL")
library(RMySQL)
conn <- dbConnect(MySQL(),
user = 'openclinic',
password = '0pen',
host = 'localhost',
port = 13306,
dbname = 'openclinic_dbo'
)
req <- dbGetQuery(conn, "SELECT * FROM concepts")
data <- dbFetch(req,n=2)
dbGetRowCount(req)
#install.packages("RMySQL")
library(RMySQL)
conn <- dbConnect(MySQL(),
user = 'openclinic',
password = '0pen',
host = 'localhost',
port = 13306,
dbname = 'openclinic_dbo'
)
res <- dbGetQuery(conn, "SELECT * FROM concepts")
data <- dbFetch(res,n=2)
dbGetRowCount(res)
install.packages("rvest")
demo(package = 'rvest')
demo(package = 'rvest', topic = 'tripadvisor')
demo(package = 'rvest', topic = 'tripadvisor')
demo(package = 'rvest')
demo(package = 'rvest', topic = 'zillow')
library(shiny); runApp('DOCS/COURS/RSCRIPT/dashboard.R')
runApp('DOCS/COURS/RSCRIPT/dashboard.R')
runApp('DOCS/COURS/RSCRIPT/dashboard.R')
install.packages('dplyr')
install.packages("dplyr")
library(shiny); runApp('DOCS/COURS/RSCRIPT/dashboard.R')
install.packages("dplyr")
runApp('DOCS/COURS/RSCRIPT/dashboard.R')
devtools::install_github("ropensci/plotly", force=TRUE)
runApp('DOCS/COURS/RSCRIPT/dashboard.R')
install.packages('httr')
install.packages("httr")
library(shiny); runApp('DOCS/COURS/RSCRIPT/dashboard.R')
runApp('DOCS/COURS/RSCRIPT/dashboard.R')
runApp('DOCS/COURS/RSCRIPT/dashboard.R')
runApp('DOCS/COURS/RSCRIPT/dashboard.R')
install.packages('sodium')
runApp('DOCS/COURS/RSCRIPT/dashboard.R')
install.packages('shinyjs')
install.packages("shinyjs")
library(shiny); runApp('DOCS/COURS/RSCRIPT/dashboard.R')
runApp('DOCS/COURS/RSCRIPT/dashboard.R')
shiny::runApp('iHAP/DEVELOPMENT/Datim-Generator v3/genv3')
runApp('iHAP/DEVELOPMENT/Datim-Generator v3/genv3')
runApp('iHAP/DEVELOPMENT/Datim-Generator v3/genv3')
runApp('iHAP/DEVELOPMENT/Datim-Generator v3/genv3')
runApp('iHAP/DEVELOPMENT/Datim-Generator v3/genv3')
runApp('iHAP/DEVELOPMENT/Datim-Generator v3/genv3')
runApp('iHAP/DEVELOPMENT/Datim-Generator v3/genv3')
PP_PREV <- "lkDqXuxu6rR"
shiny::runApp('iHAP/DEVELOPMENT/Datim-Generator v3/genv3')
runApp('iHAP/DEVELOPMENT/Datim-Generator v3/genv3')
runApp('iHAP/DEVELOPMENT/Datim-Generator v3/genv3')
runApp('iHAP/DEVELOPMENT/Datim-Generator v3/genv3')
runApp('iHAP/DEVELOPMENT/Datim-Generator v3/genv3')
View(filtered)
runApp('iHAP/DEVELOPMENT/Datim-Generator v3/genv3')
runApp('iHAP/DEVELOPMENT/Datim-Generator v3/genv3')
runApp('iHAP/DEVELOPMENT/Datim-Generator v3/genv3')
runApp('iHAP/DEVELOPMENT/Datim-Generator v3/genv3')
runApp('iHAP/DEVELOPMENT/Datim-Generator v3/genv3')
library(rsconnect)
runApp('iHAP/DEVELOPMENT/Datim-Generator v3/genv3')
deployApp()
setwd('C:/Users/ebongo/Documents/iHAP/DEVELOPMENT/Datim-Generator v3/genv3')
library(rsconnect)
deployApp()
runApp()
shiny::runApp()
runApp()
runApp()
shiny::runApp()
runApp()
shiny::runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
runApp()
shiny::runApp()
shiny::runApp()
runApp()
setwd('C:/Users/ebongo/Documents/iHAP/DEVELOPMENT/Datim-Generator v3\genv3')
setwd('C:/Users/ebongo/Documents/iHAP/DEVELOPMENT/Datim-Generator v3/genv3')
library('rsconnect')
deployApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
